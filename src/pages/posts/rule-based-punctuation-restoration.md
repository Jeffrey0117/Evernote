---
layout: ../../layouts/PostLayout.astro
title: 用 5KB 正規表達式幹掉 500MB 深度學習模型
date: 2026-01-13T11:36
description: 中文標點恢復不一定要用 AI，純規則也能達到 80% 效果，而且超級輕量
tags:
  - Python
  - 正規表達式
  - 語音辨識
---

語音辨識輸出的文字通常長這樣：

```
我跟你說啊這個東西真的很厲害你不信的話你自己試試看
```

沒有標點，一大坨。

要讀懂得自己在腦中斷句，很累。

## 正常人會怎麼做

Google 一下「中文標點恢復」，會找到一堆深度學習方案：

- [FunASR ct-punc](https://github.com/modelscope/FunASR)（阿里達摩院）
- PaddlePaddle 的 ERNIE-Punctuation
- 各種 BERT fine-tune 版本

這些模型準確度很高，但有個問題：

| 方案 | 模型大小 | 依賴 |
|------|----------|------|
| ct-punc | ~500MB | PyTorch、FunASR、一堆套件 |
| ERNIE | ~400MB | PaddlePaddle |
| BERT 類 | ~300MB+ | transformers、PyTorch |

我的應用是個 Electron 桌面軟體，已經夠肥了。

再塞一個 500MB 的深度學習模型？不行。

## 我開始想：標點規則有這麼難嗎？

仔細看中文斷句的規律，其實很有跡可循。

「我跟你說**啊**這個東西」，「啊」後面要逗號。

「這個很厲害**但是**有限制」，「但是」前面要逗號。

「你覺得**怎麼樣**」，有疑問詞，句末要問號。

這些規則，我用正規表達式就能寫。

## 規則設計

最後整理出四層規則：

### 第一層：語氣詞後面加逗號

```python
particles = ['嘛', '啦', '呀', '囉', '咯', '噢', '唷',
             '哎', '欸', '啊', '喔', '哦', '嗯', '呃']
```

「我跟你說**啊**這個很厲害」→「我跟你說啊**，**這個很厲害」

### 第二層：連接詞前面加逗號

```python
sentence_starters = [
    '然後', '但是', '所以', '不過', '可是',
    '而且', '或者', '雖然', '首先', '其次',
    '其實', '原來', '後來', '當然', '終於',
    # ... 還有很多
]
```

「這個免費**但是**有限制」→「這個免費**，**但是有限制」

### 第三層：主詞+副詞組合

這是我發現最有效的規則。

「我講完了**你就**可以開始」，「你就」前面幾乎一定要斷句。

```python
# 主詞 + 就/也/又/才/都
patterns = [
    '我就', '你就', '他就', '她就',
    '我也', '你也', '他也', '她也',
    '我才', '你才', '他才', '她才',
    # ...
]
```

這些組合在句子中間出現時，前面幾乎 100% 要加逗號。

### 第四層：重複主詞必定隔開

這是我發現最有趣的規則。

中文句子的基本結構是「主詞 + 動詞 + 受詞」。當**同一個主詞重複出現**，中間沒有連接詞，就一定要斷句。

```
我去買東西我回來了
```

兩個「我」，中間沒有「然後」「接著」這類連接詞，必須斷開：

```
我去買東西，我回來了。
```

但如果主詞之間有連接詞，就不用斷：

```
我跟他去買東西    → 不斷（「我跟他」是一個主詞）
我和她都喜歡這個  → 不斷（「我和她」是一個主詞）
我與你的約定      → 不斷（「我與你」是一個主詞）
```

所以規則是：

```python
# 連接詞：跟、和、與、及、還有、以及
connectors = ['跟', '和', '與', '及', '還有', '以及']

# 如果「我」後面緊接連接詞，就不斷
# 如果「我」後面是動詞，且後面又出現「我」，就斷
```

實作上，我用正則先檢查是否有「主詞+連接詞+主詞」的結構，有的話就保護起來不斷。

這個規則的準確度超高，因為它符合中文的基本語法邏輯。

### 第五層：結構性斷句

這層是用正則表達式匹配**句式結構**。

「每當我想起你**的時候**心裡就會難過」

這不是單純的詞彙觸發，而是「當...的時候」這個完整句式，要在「的時候」後面斷句。

```python
structural_patterns = [
    (r'(每當[^，。？！]{1,15}的時候)', r'\1，'),      # 每當...的時候
    (r'(如果[^，。？！]{1,15}的話)', r'\1，'),        # 如果...的話
    (r'(當[^，。？！]{1,15}的時候)', r'\1，'),        # 當...的時候
    (r'(雖然[^，。？！]{1,15}但是)', r'\1，'),        # 雖然...但是
]
```

這些 pattern 會匹配「當 X 的時候」整個結構，不管 X 是什麼，都在後面加逗號。

效果：

| 輸入 | 輸出 |
|------|------|
| 每當我想起你的時候心裡就難過 | 每當我想起你的時候，心裡就難過。 |
| 如果你不相信的話可以試試 | 如果你不相信的話，可以試試。 |

這才是規則式真正強大的地方：不只是詞彙匹配，還能抓句法結構。

### 第五層：句末標點

```python
question_words = ['什麼', '怎麼', '為什麼', '哪裡', '誰', '多少', '如何']
question_endings = ['嗎', '呢', '麼']

if any(w in text for w in question_words + question_endings):
    return text + '？'
else:
    return text + '。'
```

有疑問詞就問號，沒有就句號。

## 規則怎麼來的？餵小說給 AI

這些規則不是我憑空想的，是**用小說語料訓練出來的**。

我找了一堆小說片段，丟給 Claude：

```
這是一段有標點的中文小說：

「我跟你說啊，這個東西真的很厲害。」他興奮地說，「你不信的話，你自己試試看。」

請分析：哪些詞彙後面容易出現逗號？哪些詞彙前面容易出現逗號？
```

AI 會整理出規律：

```
【後面加逗號的詞彙】
- 語氣詞：啊、嘛、囉、呀
- 說話動詞後：說、道、問

【前面加逗號的詞彙】
- 轉折詞：但是、不過、可是
- 主詞+副詞：你就、他也、我才
```

餵幾十段小說，規則就越來越完整。

### 擴充規則的 SOP

如果發現某個詞彙斷句不對，不用自己想規則，直接問 AI：

```
這個句子斷句有問題：
「結果他居然成功了」→ 輸出：「結果他居然成功了。」

我覺得「結果」前面應該要有逗號，請分析這個詞的斷句規律，
並給我其他類似的詞彙。
```

AI 會回：

```
「結果」通常表示意外或轉折，前面應加逗號。

類似詞彙：
- 結果、沒想到、想不到、誰知道
- 最後、終於、總算
```

直接把這些詞加進詞表，搞定。

**用 AI 整理規則，用規則跑推理**。這才是最高效的組合。

## 處理順序很重要

一開始我踩了一個坑：

「可每當我想起你的時候」→ 被拆成「可，每當我想起你的時候」

「可」被當成轉折詞，但這裡的「可每當」是完整結構。

解法是**長詞優先匹配**：

```python
# 先處理長詞，再處理短詞
long_patterns = ['可每當', '可每次', '換句話說', '比如說', '沒想到']
short_patterns = ['可是', '每當', '每次']
```

另外還有保護詞機制：

```python
protected_words = ['自然而然', '理所當然', '順其自然']
```

這些詞裡面有「然」「當」，但不應該被拆開。

## 效果對比

來看實際效果：

| 輸入 | 規則式輸出 | ct-punc 輸出 |
|------|------------|--------------|
| 我跟你說啊這個東西真的很厲害 | 我跟你說啊，這個東西真的很厲害。 | 我跟你說啊，這個東西真的很厲害。 |
| 這個工具免費但是有額度 | 這個工具免費，但是有額度。 | 這個工具免費，但是有額度。 |
| 你覺得這樣好不好 | 你覺得這樣好不好？ | 你覺得這樣好不好？ |

對於**口語化的句子**，規則式的效果跟深度學習差不多。

當然，遇到複雜的書面語，深度學習還是比較強。但語音辨識輸出本來就偏口語，規則式夠用了。

## 數據比較

| 項目 | 規則式 | ct-punc |
|------|--------|---------|
| 程式大小 | **5KB** | ~500MB |
| 依賴 | 只要 `re` 模組 | PyTorch、FunASR |
| 啟動時間 | 瞬間 | 3-5 秒 |
| 處理速度 | 每秒幾萬句 | 每秒幾百句 |
| 準確度 | ~80% | ~95% |
| 可調整性 | 改詞表就好 | 要重新訓練 |

80% 的準確度換來 100 倍的輕量化，值得。

## 什麼時候該用規則式

**適合規則式的場景：**
- 語音辨識輸出（偏口語）
- 資源受限的環境（手機、嵌入式）
- 需要即時處理
- 想要可解釋、可調整

**適合深度學習的場景：**
- 正式書面文章
- 需要極高準確度
- 有充足的運算資源

我的做法是**兩者並用**：優先用 ct-punc，如果環境不支援就 fallback 到規則式。

---

調了一堆詞表之後，我把這套規則整理成一個獨立模組：

GitHub Repo: [Jeffrey0117/biaodian](https://github.com/Jeffrey0117/biaodian)

只有 5KB，零依賴，直接 `import` 就能用。

```python
from punctuation import add_punctuation

result = add_punctuation("我跟你說啊這個東西真的很厲害")
# 輸出: "我跟你說啊，這個東西真的很厲害。"
```

如果發現某個詞彙斷句不對，直接改詞表：

```python
from punctuation import add_particle, add_sentence_starter

add_particle("耶")           # 「耶」後面加逗號
add_sentence_starter("結果")  # 「結果」前面加逗號
```

不用重新訓練模型，改完立刻生效。

這大概是我寫過最有成就感的「小工具」。用最簡單的方法解決問題，不用無腦套 AI。
