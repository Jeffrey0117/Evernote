---
layout: ../../layouts/PostLayout.astro
title: 優化方法論：從語音辨識學到的事
date: 2026-01-13T12:45
description: 從 FunASR、Sherpa-ONNX 的優化經驗，抽出可複用的優化思維框架
tags:
  - 效能優化
  - 方法論
---

做了幾個月的語音辨識優化，踩了無數坑。

回頭看，很多教訓其實是通用的。這篇把這些經驗抽象成「優化方法論」。

## 原則一：優化 = 找瓶頸

不要亂槍打鳥。先找出**真正的瓶頸**在哪。

在 [FunASR 優化](/Evernote/posts/funasr-optimization-guide)裡，我發現最大的瓶頸是**初始化時間**，不是推理速度。

三個模型順序載入要 15 秒。改成並行載入，直接砍到 5 秒。

如果我只顧著優化推理速度，永遠不會發現這個問題。

**方法**：先量測，再優化。用 profiler、用 log、用計時器，找出時間花在哪。

## 原則二：同技術，不同效果

同樣的優化技術，在不同場景下可能完全相反。

在 [Sherpa-ONNX 優化](/Evernote/posts/sherpa-onnx-optimization)裡：

| 模型 | int8 量化效果 |
|------|---------------|
| Paraformer（離線） | 加速 2 倍，品質不變 |
| Zipformer（串流） | 輸出亂碼，完全不能用 |

原因是架構不同。Paraformer 一次看完整段音頻，量化誤差被上下文修正。Zipformer 每次只看一小段，誤差累積爆炸。

**方法**：不要無腦套用「最佳實踐」。理解技術原理，判斷是否適用於你的場景。

## 原則三：一次只改一個變數

這是我在[串流語音辨識的參數調教之路](/Evernote/posts/streaming-speech-recognition-optimization)學到最痛的教訓。

當時我同時改了四個東西：

- 發送間隔 250ms → 150ms
- 緩衝大小 4096 → 2048
- 端點偵測調激進
- 換成 int8 模型

結果品質崩壞，根本不知道是誰的問題。

花了半天回滾、一個一個測，才發現是 int8 的鍋。

**方法**：改一個，測一個。確認沒問題，再改下一個。慢就是快。

## 原則四：先求穩，再求快

使用者寧可等 0.5 秒看到正確的字，也不要瞬間看到亂碼。

在串流辨識裡，我最後選了 fp32 而不是 int8。雖然慢一點，但品質穩定。

**方法**：先讓功能正確運作，再考慮優化。過早優化是萬惡之源。

## 原則五：VAD 是低垂的果實

不管用什麼辨識引擎，**跳過靜音**幾乎都是最划算的優化。

在我的測試裡，VAD 平均跳過 20-40% 的音頻。等於直接提升 20-40% 的速度，而且不影響品質。

**方法**：在送進模型之前，先過濾掉不需要處理的資料。這個思路適用於任何領域。

## 原則六：執行緒數有甜蜜點

不管是 FunASR 還是 Sherpa-ONNX，執行緒數都不是越多越好。

實測發現上限大約是 8。超過之後，執行緒切換的開銷反而拖慢速度。

**方法**：找到甜蜜點，不要貪心。資源不是越多越好。

## 框架：優化 SOP

根據這些原則，整理出一套 SOP：

```
1. 量測：找出瓶頸在哪
   ↓
2. 假設：這個瓶頸可以怎麼解決？
   ↓
3. 驗證：只改一個變數，測試效果
   ↓
4. 確認：品質沒問題嗎？穩定嗎？
   ↓
5. 迭代：回到步驟 1，找下一個瓶頸
```

這套流程看起來很慢，但實際上最快。因為不會走冤枉路。

---

這些原則不只適用於語音辨識。任何效能優化，都可以套用這個框架。

希望這篇能幫到同樣在跟效能奮戰的人。

---

相關實戰文章：

- [Sherpa-ONNX 雙模型架構優化實戰](/Evernote/posts/sherpa-onnx-optimization)
- [FunASR 極限優化指南](/Evernote/posts/funasr-optimization-guide)
- [串流語音辨識的參數調教之路](/Evernote/posts/streaming-speech-recognition-optimization)

---

<small>（自己備註：VAD 節省 20-40%、執行緒數上限 8 這些數據是從其他文章引用的，那邊也是唬爛的。原則和框架是真的。）</small>
