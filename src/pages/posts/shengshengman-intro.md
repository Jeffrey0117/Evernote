---
layout: ../../layouts/PostLayout.astro
title: 聲聲慢：我做了一個離線語音轉文字工具
date: 2026-01-13T15:00
description: 邊講邊出字、完全離線、隱私優先的語音辨識桌面應用
tags:
  - 產品
  - Electron
  - 語音辨識
---

我做了一個語音轉文字的桌面應用，叫**聲聲慢**。

這篇介紹它是什麼、為什麼做、有什麼特點。

## 聲聲慢是什麼？

一句話：**離線的語音轉文字工具**。

按下快捷鍵開始錄音，講完自動轉成文字，貼到你正在打字的地方。

不用連網路，不用擔心隱私。

## 為什麼做這個？

我每天要打很多字：寫文件、回訊息、寫程式註解。

打字很慢，講話比較快。

市面上有很多語音輸入工具，但都有問題：

| 工具 | 問題 |
|------|------|
| 手機內建 | 只能在手機上用 |
| Google Docs 語音輸入 | 要連網、要開瀏覽器 |
| macOS 聽寫 | 中文辨識不夠好 |
| 訊飛輸入法 | 資料傳到中國伺服器 |
| Whisper | 要自己架、沒有 UI |

我想要的是：

- **桌面應用**：在任何地方都能用
- **離線**：不用擔心隱私
- **中文好**：專門針對中文優化
- **邊講邊出字**：即時看到辨識結果

找不到，就自己做。

## 核心功能

### 1. 邊講邊出字

不用等錄完才看到結果。講的同時，文字就會出現。

這樣可以即時知道有沒有辨識錯，不用講完一大段才發現歪掉。

### 2. 完全離線

所有辨識都在本機完成，音頻不會傳到任何伺服器。

你在咖啡廳講公司機密也沒關係。

### 3. 自動貼上

辨識完成後，自動把文字貼到你正在打字的地方。

不用手動複製貼上，省一個步驟。

### 4. 熱詞支援

可以自訂專有名詞，提高辨識率。

常講「聲聲慢」「React」「TypeScript」？加進熱詞就不會辨識錯。

### 5. 歷史記錄

所有辨識過的文字都會存下來，可以回頭找。

「我剛剛講了什麼來著？」→ 打開歷史記錄就有。

## 技術棧

底層的語音辨識用 [Sherpa-ONNX](https://github.com/k2-fsa/sherpa-onnx)，一個基於 ONNX Runtime 的離線辨識框架。

整個優化過程寫在這個系列：[所有你應該知道的語音辨識，都在這](/Evernote/posts/speech-recognition-series-index)。

簡單講：

- **離線辨識**：Paraformer 模型
- **串流辨識**：Zipformer 模型
- **標點恢復**：規則式 + ct-punc
- **簡繁轉換**：OpenCC

這套組合的辨識速度是實時的 10 倍以上，講 10 秒只要不到 1 秒就能處理完。

## 目前狀態

聲聲慢目前是**桌面版**，支援 Windows 和 macOS。

我自己每天都在用，邊開發邊吃自己的狗糧。

## 未來計畫

### 📱 APP 版

計畫做 iOS 和 Android 版本。

Sherpa-ONNX 本身就支援移動平台，技術上可行。

主要挑戰是：
- 模型太大，要做壓縮
- 手機的運算資源有限，要再優化
- iOS 的背景錄音限制

這是下一階段的重點。

### 🌐 更多語言

目前只支援中文（繁體/簡體）和英文。

之後考慮加入日文、韓文等。

### 🔌 更多整合

計畫做 VS Code 插件、Obsidian 插件，讓語音輸入更無縫。

## 為什麼叫聲聲慢？

取自李清照的詞牌名《聲聲慢》。

「聲聲」是語音，「慢」是慢慢來、不急。

語音辨識不用追求瞬間完成，穩定準確比較重要。先求穩，再求快。

這也是我做這個產品的理念。

---

如果你有興趣試用，或是有任何建議，歡迎聯繫我。

相關技術文章：

- [所有你應該知道的語音辨識，都在這](/Evernote/posts/speech-recognition-series-index)
- [Sherpa-ONNX 雙模型架構優化實戰](/Evernote/posts/sherpa-onnx-optimization)
- [串流語音辨識的參數調教之路](/Evernote/posts/streaming-speech-recognition-optimization)

---

<small>（自己備註：APP 版是未來計畫，記得要做）</small>
